import torch
from typing import Optional, Callable, List, Dict

from graph_nets.data_structures.attribute import Attribute
from graph_nets.data_structures.edge import Edge
from graph_nets.data_structures.utils import lists_equal
from graph_nets.data_structures.node import Node


class Graph:
    """
    Following the DeepMind "Graph Nets" paper (https://arxiv.org/abs/1806.01261).
    This graph is a directed, attributed multi-graph with a global attribute.
    Directed, because edges distinguish between sender and receiver. An attribute can be 'any' information. Multi-graph,
    because there can be more than one edge between vertices, including self-edges.
    """

    def __init__(self, nodes: List[Node], edges: List[Edge], attr: Optional[Attribute] = None):
        if attr is None:
            attr = Attribute(val=None)

        assert isinstance(nodes, list) and isinstance(edges, list), "Nodes and edges must be lists"

        self.nodes = set(nodes)  # V
        self.edges = set(edges)  # E
        self.attr = attr  # e

        # store ordered representations for easy alignment of two graphs with equal structure
        self.ordered_nodes = nodes
        self.ordered_edges = edges

        self.device: torch.device = None

        self._check_integrity()

    def _check_integrity(self) -> None:
        """
        Validates the internal state of the graph and raises a ValueError if it is inconsistent.
        """
        self._check_node_edge_integrity()
        self._check_ordered_references_integrity()

    def _check_node_edge_integrity(self) -> None:
        """
        Checks whether the nodes corresponding to edges of this graph are also contained in the set of nodes.
        Put differently, edges must only connect nodes of this graph.
        """
        for edge in self.edges:
            if edge.receiver not in self.nodes or edge.sender not in self.nodes:
                raise ValueError("Edges must only connect nodes that are contained in the graph")

    def _check_ordered_references_integrity(self) -> None:
        """
        The graph stores a list (ordered) and a set of both nodes and edges, for the sake of easier comparison with
        other graphs. This method validates whether lists and sets are 'aligned' with each other, i.e. contain exactly
        the same elements.
        """
        if len(self.ordered_edges) != len(self.edges):
            raise ValueError("Number of ordered edges must be equal to the number of edges in the hash set")

        if len(self.ordered_nodes) != len(self.nodes):
            raise ValueError("Number of ordered nodes must be equal to the number of nodes in the hash set")

        for e in self.ordered_edges:
            if e not in self.edges:
                raise ValueError("Every edge in edges_ordered must be contained in edges")

        for n in self.ordered_nodes:
            if n not in self.nodes:
                raise ValueError("Every node in nodes_ordered must be contained in nodes")

    def add_node(self, new_node: Node) -> None:
        new_node.to(self.device)
        self.nodes.add(new_node)
        self.ordered_nodes.append(new_node)
        self._check_integrity()

    def add_edge(self, new_edge: Edge) -> None:
        new_edge.to(self.device)
        self.edges.add(new_edge)
        self.ordered_edges.append(new_edge)
        self._check_integrity()

    def add_reflexive_edges(self, attribute_generator: Optional[Callable[[Node], Attribute]] = None):
        if attribute_generator is None:
            attribute_generator = lambda _: Attribute()

        for n in self.nodes:
            e = Edge(n, n, attribute_generator(n))
            self.add_edge(e)

    def add_all_edges(self, reflexive: bool = True,
                      attribute_generator: Optional[Callable[[Node, Node], Attribute]] = None) -> None:
        """
        Modifies the graph in-place, such that it is fully connected, adding n^n edges, where n is the number of nodes.
        :param reflexive: Whether to connect nodes to themselves
        :param attribute_generator: New edges will be given an attribute generated by the attribute generator
        """
        if attribute_generator is None:
            attribute_generator = lambda sn, rn: Attribute()

        for n1 in self.nodes:
            for n2 in self.nodes:
                if not reflexive and n1 == n2:
                    continue
                e = Edge(n1, n2, attribute_generator(n1, n2))
                self.add_edge(e)

    def remove_all_edges(self) -> None:
        """
        Modifies the graph in-place, such that all edges are gone.
        Performs an integrity check afterwards.
        """
        self.edges = set()
        self.ordered_edges = []
        for n in self.nodes:
            n.receiving_edges = set()
            n.sending_edges = set()

        self._check_integrity()

    def to(self, device: torch.device) -> 'Graph':
        """
        Moves torch values of this object to the specified device (e.g. GPU).
        """
        self.device = device
        self.attr.to(device)
        for edge in self.edges:
            edge.to(device)
        for node in self.nodes:
            node.to(device)
        return self

    def asdict(self) -> Dict:
        return {
            'attr': self.attr.asdict(),
            'nodes': {hash(n): n.asdict() for n in self.ordered_nodes},
            'edges': [e.asdict() for e in self.ordered_edges]
        }

    @staticmethod
    def from_dict(d: Dict) -> 'Graph':
        nodes_dict = {k: Node.from_dict(node_dict) for k, node_dict in d['nodes'].items()}
        nodes = list(nodes_dict.values())
        edges = [Edge.from_dict(e, nodes_dict) for e in d['edges']]
        attr = Attribute.from_dict(d['attr'])
        return Graph(nodes, edges, attr)

    def __eq__(self, g2: object) -> bool:
        if not isinstance(g2, Graph):
            return False

        g1 = self
        g1._check_integrity()
        g2._check_integrity()

        if not lists_equal(g1.ordered_nodes, g2.ordered_nodes, comparator=Node.eq_attr):
            return False

        if not lists_equal(g1.ordered_edges, g2.ordered_edges, comparator=Edge.eq_attr_and_ctx):
            return False

        return True

    def __repr__(self) -> str:
        return "graph({})".format(self.attr.__repr__())

    def __del__(self) -> None:
        """
        Ensures garbage collection of CUDA tensors that this graph contains. If the tensors are not moved to CPU,
        they remain on the GPU even after this object is garbage collected.
        """
        try:
            self.to(device=torch.device('cpu'))
        except AttributeError:
            pass
