\section{Method}

This section describes our approach to solving the pagerank estimation problem. We present our methodology as we have applied it to the problem at hand, as opposed to extracting the generic, underlying principles, as these are mostly covered in the background section of this document.

The pagerank estimation problem is, given a webpage represented as an attributed graph with screenshots, to estimate the global popularity of that webpage.
Our ground-truth for \textit{popularity} is a list containing 100,000 webpages, created by Open PageRank.
More details can be found in Section \ref{OpenPageRank}.
The given data has several characteristics which have influenced our way of tackling the problem:

\begin{itemize}
    \item With approximately 100,000 samples, there is plenty of data available. The number of images is even higher, since a single sample can consist of up to 16 images.
    \item The problem is a ranking task. Samples need to be ordered and during inference the rank of a (possibly) unseen sample must be predicted.
    \item Images make up the majority of the information contained in the dataset. Neural networks, in particular convolutional neural networks (CNNs; see \cite{lecun1989backpropagation}) are performing well at processing images and at extracting features from them. With \cite{krizhevsky:imagenet} they have become the de-factor standard way of solving image classification problems where ever large datasets are available.
    \item The samples are variably-sized and can be easily represented as a graph: The number of screenshots taken from a domain may vary depending on the number of subpages. Links between subpages can be represented as edges in a graph. Naturally, the samples can be seen as graphs and a model capable of using the entire information from the graph seems best suited.
    \item The data is relatively noisy, e.g. samples might be mostly black or ranks might be inaccurate (as they are subject to change over time anyways).
\end{itemize}

Motivated by the stated observations, we decided to use a combination of CNN and graph network (GN) (see \cite{deepmind:graphnets}), trained with ranking loss functions, to predict pageranks.

Learning features as opposed to hand-engineering them seems reasonable as it is unknown to us what the visual elements are that distinguish popular and unpopular webpages. Furthermore, a dataset containing more than 1,000,000 images provides more than enough training data to work with high-capacity models, capable of learning complex features.

While many of today's CNN-papers deal with natural images, e.g. \cite{gu2018ava,szegedy2017inception,openai:learningdexterity}, there have been applications with computer generated images as well. \cite{beltramelli:pix2code} converts a screenshot into a fixed size feature vector. Therefore, CNNs seem very suitable for screenshot processing as well and are our choice.

Graph networks are suitable for dealing with the image graph. Arbitrary size, arbitrary pieces of information (we use only images, theoretically text, etc. can be used as well).

Ranking problem requires special losses.

We define an accuracy metric that allows us to evaluate the performance of our model. It measures how accurate the model ranks any two given webpages from a subset of the dataset relative to each other.

While our dataset contains webpages from domains which are (or have been) publicly available on the web, we want it to work with unseen inputs as well. The goal of our model's inference mode is to either estimate the absolute popularity of a webpage with respect to the top 100,000 webpages or, secondly, compare two (or more) given webpages relative to one and another.

\begin{figure}
    \centering

    \begin{tikzpicture}[]

        \draw[dashed] (0,-1) rectangle (6,1);
        
        % inputs and outputs
        \node (in_data) at (-1,0.5) [draw,process]{Dataset};
        \node (in_inference) at (-1,-.5) [draw,process]{Inference};
        \node (out_loss) at (7,1) [draw,process]{Loss};
        \node (out_accuracy) at (7,0) [draw,process]{Accuracy};
        \node (out_rank) at (7,-1) [draw,process]{Rank};
        
        % processing
        \node (cnn) at (1,0) [text width=1.65cm, align=center, draw, process]{Screenshot feature extractor};
        \node (gn) at (3,0) [text width=1.5cm, align=center, draw, process]{Graph network};
        \node (pred) at (5,0) [draw, process]{Output};

        % edges
        \draw[->] (in_data) -- (cnn);
        \draw[->] (in_inference) -- (cnn);
        \draw[->] (cnn) -- (gn);
        \draw[->] (gn) -- (pred);
        \draw[->] (pred) -- (out_loss);
        \draw[->] (pred) -- (out_rank);
        \draw[->] (pred) -- (out_accuracy);

    \end{tikzpicture}
    \caption[Webpage rank prediction model architecture overview]{Overview of the components of our webpage rank prediction model. Input to the model is either the pagerank dataset or one/several samples during inference. The model processes the inputs with the screenshot feature extractor, here a convolutional neural network (CNN), followed by a graph network which deals with the graph structure of the data, yielding a fixed-size output. The output is used to compute loss and accuracy (when training), or estimate a rank (during inference). The dashed box separates the model from the components orchestrating it.}
    \label{fig:methodcomponents}
\end{figure}

The remainder of this section describes the components of our model in greater detail. Figure \ref{fig:methodcomponents} gives an overview.

\subsection{Screenshot Feature Extractor}

Feature extractor is a component in this model. Applied node-wise to the inputs. It is a neural network itself, no specifics yet, roughly inputs and outputs

Idea of feature extraction is borrowed from pre-trained models. Distinction from pre-training: we train on a separate, but very similar task. Two methods: train end-to-end or pre-train

Mathematical notation, clarify inputs and outputs.

Model architecture (+figure)

Generation of batches from variably-sized graphs, weighting

Training of the feature extractor

\subsection{Graph Network Blocks}

Where the GN blocks are positioned in the model, first layer to make use of the graph structure, nodes are from feature extractor. Inputs and outputs, formal definition.

Baseline GN block; maps to scalar and aggregates. Intuition: looking a single images and ranking based on them + avg. +figure

Full GN block; more complex: Block definition with concat and avg/max aggregation. Dense layers everywhere. Reflexive graph for avg (to avoid 0 edge count). +figure

Intuition behind the block: Information flows, global state is sort of an aggregation.

Weight-sharing between consecutive blocks or not.

Conversion into a fixed-size output using the global attribute (output block).

Interpretation of the feature extractor as a special kind of block, bring up the encoder-core-decoder scheme from the GN DeepMind example.

(potentially +figure, if it adds any value)

\subsection{Loss Function}

Loss function is in a ranking setting. We chose pairwise because initial experiments showed that pointwise resulted in unstable training. Derive the loss function in the following.

Dataset vector, computation of the output matrix, ..., weighting w

Sum aggregation, final loss scalar normalized

Additional weighting term w, chosen as bla bla, with log base. Plot with linear and log in comparison (axis: 1-100k, 0-1). Intuition is that the top 10k samples contain more information than the e.g. 80k-90k.

Approximation with mini-batches, number of comparisons grows quadratically so larger batches are desirable. Also regularizing effect, as always.

Note that this is single scalar supervision (or binary classification) and it effectively trains a CNN.

\subsection{Evaluation Metrics and Inference}

Accuracy is computed by feeding all samples through the model, large vec. Then matrix and ground-truth matrix comparison. Number of correct pairwise results.

Advantage: Can be easily compared to humans, however difficulty is not taken into consideration, e.g. 80,001 and 80,000 are extremely hard/impossible. Band of growing width that masks out the close samples.

Formal definition of inference, i.e. sample $x$ to rank or pairwise and listwise. 

Pairwise: feed both samples, magnitude of difference is certainty, sign is relative ranking.

Pointwise: requires ground truth, pairwise with everyone, come up with something here...
